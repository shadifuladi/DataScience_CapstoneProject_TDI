{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn import metrics\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dill \n",
    "\n",
    "df = dill.load(open('df_sentiments.pkd', 'rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='green'> Machine Learning Model </font> \n",
    "\n",
    "\n",
    "In this notebook, [Scikit Learn Random Forest Classifier](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html) is tunned to predict the lease status of each channel, using the following features: \n",
    "\n",
    "  - User role (applicant or resident),\n",
    "  - Response time,\n",
    "  - Conversation length,\n",
    "  - Message length,\n",
    "  - Average sentiment score for a text,\n",
    "  - Frequency of sentiment score of all sentences within each message in 5 classes: very negative, negative, neutral, positive, very positive. \n",
    "    \n",
    "The data set include a total of 180K observations and 10 features. The data set is divided into train and test (90%:10%) sets manually in order to assure that messages corresponding to the same channel are kept together. The categorical featuers (the user status) are preprocessed and transformed via [One Hot Encoder algorithm](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OneHotEncoder.html). \n",
    "\n",
    "The hyperparameters are first narrowed down using [Randomized Search Cross Validation](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.RandomizedSearchCV.html) and further optimized via [Grid Search](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html) both provided in the python Scikit Learn library. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_to_use = ['is_applicant', 'response_time','convo_length',\n",
    "                   'convo_num', 'num_sentence', 'num_words',\n",
    "                   'expected_sentiment_text', 'sigma_sentiment_text',\n",
    "                   'freq-very_negative', 'freq-negative',\n",
    "                   'freq-neutral', 'freq-positive', 'freq-very_positive']\n",
    "X = df[features_to_use]\n",
    "y = df['is_lease'].replace({'Leased' :1 , \n",
    "                            'Leased Other Room':1, \n",
    "                            'No Lease':0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# D\n",
    "X_train = X[:164645]\n",
    "y_train = y[:164645]\n",
    "\n",
    "X_test = X[164645:]\n",
    "y_test = y[164645:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Transforming the categorical features\n",
    "\n",
    "transformer_name = 'ohe_on_all_categorical_features'\n",
    "transformer = OneHotEncoder(sparse=False)\n",
    "columns_to_encode = ['is_applicant']\n",
    "\n",
    "ohe_final = ColumnTransformer([\n",
    "            (transformer_name, transformer, columns_to_encode)], \n",
    "            remainder='passthrough')\n",
    "\n",
    "ohe_final.fit_transform(X);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dividing the data set into train and test (90%:10%),\n",
    "# keeping messages of the same channel in the same set. \n",
    "\n",
    "X_train = X[:164645]\n",
    "y_train = y[:164645]\n",
    "\n",
    "X_test = X[164645:]\n",
    "y_test = y[164645:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## set up evaluation functions for predictions \n",
    "\n",
    "def model_evaluation(model, X, y_true):\n",
    "    y_pred = model.predict(X)\n",
    "    scores = {}\n",
    "    scores['accuracy'] = round(metrics.accuracy_score(y_true, y_pred), 4)\n",
    "    scores['precision'] = round(metrics.precision_score(y_true, y_pred), 4)\n",
    "    scores['recall'] = round(metrics.recall_score(y_true, y_pred), 4)\n",
    "    probs = model.predict_proba(X).T[1]\n",
    "    precisions, recalls, thresholds = metrics.precision_recall_curve(y_true, probs)\n",
    "    scores['area under precision-recall curve'] = round(metrics.auc(recalls, precisions), 4)\n",
    "    return scores\n",
    "\n",
    "def print_model_evaluation(model_name, scores):\n",
    "    print('{} evaluation \\n'.format(model_name))\n",
    "    for metric, score in scores.items():\n",
    "        print('Test {}: {}'.format(metric, score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Use randomized search CV to ... \n",
    "\n",
    "rf_pipe = Pipeline([('ohe', ohe_final),\n",
    "                    ('rf', RandomForestClassifier())])\n",
    "\n",
    "random_grid = {'n_estimators': [int(x) for x in np.linspace(200, 2000, 10)],\n",
    "               'max_features': ['auto', 'sqrt'],\n",
    "               'max_depth': range(1, 10),\n",
    "               'min_samples_split': [2, 5, 10],\n",
    "               'min_samples_leaf': [1, 2, 4],\n",
    "               'bootstrap': [True, False]}\n",
    "\n",
    "\n",
    "rf_random = RandomizedSearchCV(estimator = RandomForestClassifier(), \n",
    "                               param_distributions = random_grid,\n",
    "                               n_iter = 100, \n",
    "                               cv = 3, \n",
    "                               verbose=2, \n",
    "                               random_state=42, \n",
    "                               n_jobs = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_pipe = Pipeline([('ohe', ohe_final),\n",
    "                    ('rf', RandomForestClassifier(n_estimators=1000, random_state=42))])\n",
    "\n",
    "rf_gs = GridSearchCV(rf_pipe, \n",
    "                     cv=5, \n",
    "                     param_grid={'rf__max_depth': range(1, 10),\n",
    "                                 'rf__n_estimators': [int(x) for x in np.linspace(200, 2000, 10)],\n",
    "                                 'rf__bootstrap' : [True, False]}\n",
    "                    )\n",
    "\n",
    "\n",
    "rf_gs.fit(X_train, y_train)\n",
    "print(\"The best hyperparameter value is: \", rf_gs.best_params_)\n",
    "\n",
    "rf_gs_scores = model_evaluation(rf_gs, X_test, y_test)\n",
    "print_model_evaluation('Random forest', rf_gs_scores)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
